backend: theano
class_name: Sequential
config:
- class_name: Bidirectional
  config:
    batch_input_shape: !!python/tuple [null, 20, 21]
    dtype: float32
    layer:
      class_name: GRU
      config:
        activation: tanh
        activity_regularizer: null
        bias_constraint: null
        bias_initializer:
          class_name: Zeros
          config: {}
        bias_regularizer: null
        dropout: 0.0
        go_backwards: false
        implementation: 0
        kernel_constraint: null
        kernel_initializer:
          class_name: VarianceScaling
          config: {distribution: uniform, mode: fan_avg, scale: 1.0, seed: null}
        kernel_regularizer: null
        name: gru_1
        recurrent_activation: hard_sigmoid
        recurrent_constraint: null
        recurrent_dropout: 0.0
        recurrent_initializer:
          class_name: Orthogonal
          config: {gain: 1.0, seed: null}
        recurrent_regularizer: null
        return_sequences: false
        stateful: false
        trainable: true
        units: 64
        unroll: false
        use_bias: true
    merge_mode: concat
    name: bidirectional_1
    trainable: true
- class_name: Dense
  config:
    activation: linear
    activity_regularizer: null
    bias_constraint: null
    bias_initializer:
      class_name: Zeros
      config: {}
    bias_regularizer: null
    kernel_constraint: null
    kernel_initializer:
      class_name: VarianceScaling
      config: {distribution: uniform, mode: fan_avg, scale: 1.0, seed: null}
    kernel_regularizer: null
    name: dense_1
    trainable: true
    units: 5
    use_bias: true
- class_name: Activation
  config: {activation: softmax, name: activation_1, trainable: true}
keras_version: 2.0.4
