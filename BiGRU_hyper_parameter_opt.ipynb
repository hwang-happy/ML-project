{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'theano'\n",
    "import keras\n",
    "from keras.layers.recurrent import LSTM, SimpleRNN, GRU\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.wrappers import Bidirectional, TimeDistributed\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, RepeatVector\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proteins = [\"*\"]\n",
    "structures = [\"*\"]\n",
    "\n",
    "\n",
    "\n",
    "path = \"output5597.out\"\n",
    "with open(path) as f:\n",
    "    for line in f:\n",
    "        splited = line.strip().split(' ')\n",
    "        if len(list(splited[1])) == len(list(splited[2])):\n",
    "            proteins.extend(list(splited[1].upper()))\n",
    "            proteins.extend(['*']*10)\n",
    "            structures.extend(list(splited[2].upper()))\n",
    "            structures.extend(['*']*10)\n",
    "        \n",
    "            \n",
    "            \n",
    "alphabet_structures = ['C', 'H', 'E', 'T', \"*\"]\n",
    "alphabet_proteins = ['A','R','N','D', 'C', 'E', 'Q', 'G', 'H', 'I', 'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V', '*']\n",
    "\n",
    "known_proteins = []\n",
    "known_structures = []\n",
    "for i in range(len(proteins)):\n",
    "    if proteins[i] in alphabet_proteins and structures[i] in alphabet_structures:\n",
    "        known_proteins.append(proteins[i])\n",
    "        known_structures.append(structures[i])\n",
    "proteins = known_proteins\n",
    "structures = known_structures\n",
    "\n",
    "structures_indices = dict((c, i) for i, c in enumerate(alphabet_structures))\n",
    "indices_structures = dict((i, c) for i, c in enumerate(alphabet_structures))\n",
    "\n",
    "proteins_indices = dict((c, i) for i, c in enumerate(alphabet_proteins))\n",
    "indices_proteins = dict((i, c) for i, c in enumerate(alphabet_proteins))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for mem_depth in [12,16,20]:\n",
    "\n",
    "    #Get time series\n",
    "    protein_blocks = []\n",
    "    structure = []\n",
    "    for i in range(0, len(proteins) - mem_depth + 1):\n",
    "        protein_blocks.append(proteins[i: i + mem_depth])\n",
    "        structure.append(structures[i + int(mem_depth/2) - 1])\n",
    "\n",
    "\n",
    "    #Vectorisation\n",
    "    X = np.zeros((len(protein_blocks), mem_depth, len(alphabet_proteins)), dtype=np.bool)\n",
    "    y = np.zeros((len(structure), len(alphabet_structures)), dtype=np.bool)\n",
    "    for i, block in enumerate(protein_blocks):\n",
    "        for t, protein in enumerate(block):\n",
    "            X[i, t, proteins_indices[protein]] = 1\n",
    "        y[i, structures_indices[structure[i]]] = 1\n",
    "\n",
    "    \n",
    "    for nodes in [64,128,256]:\n",
    "        for learning_rate in [0.1, 0.01, 0.001]:\n",
    "            for momentum_val in [0.3, 0.6, 0.9]:\n",
    "                print('Build model...')\n",
    "                \n",
    "                \n",
    "                print(\"Nodes: {0} LR: {1} MV: {2}\".format(nodes, learning_rate, momentum_val))\n",
    "                for i in range(3):\n",
    "                    \n",
    "                    model = Sequential()\n",
    "                    model.add(Bidirectional(GRU(nodes), input_shape=(mem_depth, len(alphabet_proteins))))\n",
    "                    model.add(Dense(len(alphabet_structures)))\n",
    "                    model.add(Activation('softmax'))\n",
    "\n",
    "                    optimizer = SGD(lr=learning_rate, momentum=momentum_val)\n",
    "\n",
    "                    model.compile(loss='categorical_crossentropy', optimizer=optimizer) \n",
    "                    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, train_size=0.1)\n",
    "                    model.fit(X_train, y_train, batch_size=128, epochs=5)\n",
    "                    test_filtered_x = np.array([X_test[i] for i in range(len(X_test)) if alphabet_structures[np.argmax(y_test[i])] != '*'])\n",
    "                    test_filtered_y = np.array([y_test[i] for i in range(len(y_test)) if alphabet_structures[np.argmax(y_test[i])] != '*'])\n",
    "                    predictions = (model.predict(test_filtered_x))\n",
    "                    predictions = [alphabet_structures[np.argmax(prediction)] for prediction in predictions]\n",
    "                    test_filtered_y = [alphabet_structures[np.argmax(y)] for y in test_filtered_y]\n",
    "                    print(\"TEST SET ACC:\")\n",
    "                    print(np.mean(np.array(predictions) == test_filtered_y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wynik w pliku Eval_stage_1_result.txt\n",
    "\n",
    "Obiecujące wyniki to wszystkie o LR = 0.1 oraz te spośród LR=0.01, które mają momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Nodes: 64 LR: 0.01 MV: 0.9\n",
      "Epoch 1/10\n",
      "113198/113198 [==============================] - 35s - loss: 1.2810    \n",
      "Epoch 2/10\n",
      "113198/113198 [==============================] - 34s - loss: 1.1565    \n",
      "Epoch 3/10\n",
      " 32512/113198 [=======>......................] - ETA: 23s - loss: 1.1404"
     ]
    }
   ],
   "source": [
    "##Etap drugi, sprawdzenie przypadków LR = 0.01, momentum = 0.9 na podstawie 10 epok.\n",
    "\n",
    "###DUE TO LACK OF ELECTRICITY  mem_depth = 12 was done separately\n",
    "for mem_depth in [16,20]:\n",
    "\n",
    "    #Get time series\n",
    "    protein_blocks = []\n",
    "    structure = []\n",
    "    for i in range(0, len(proteins) - mem_depth + 1):\n",
    "        protein_blocks.append(proteins[i: i + mem_depth])\n",
    "        structure.append(structures[i + int(mem_depth/2) - 1])\n",
    "\n",
    "\n",
    "    #Vectorisation\n",
    "    X = np.zeros((len(protein_blocks), mem_depth, len(alphabet_proteins)), dtype=np.bool)\n",
    "    y = np.zeros((len(structure), len(alphabet_structures)), dtype=np.bool)\n",
    "    for i, block in enumerate(protein_blocks):\n",
    "        for t, protein in enumerate(block):\n",
    "            X[i, t, proteins_indices[protein]] = 1\n",
    "        y[i, structures_indices[structure[i]]] = 1\n",
    "\n",
    "  \n",
    "    for nodes in [64,128,256]:\n",
    "        for learning_rate in [0.01]:\n",
    "            for momentum_val in [0.9]:\n",
    "                print('Build model...')\n",
    "                \n",
    "                \n",
    "                print(\"Nodes: {0} LR: {1} MV: {2}\".format(nodes, learning_rate, momentum_val))\n",
    "                for i in range(3):\n",
    "                    \n",
    "                    model = Sequential()\n",
    "                    model.add(Bidirectional(GRU(nodes), input_shape=(mem_depth, len(alphabet_proteins))))\n",
    "                    model.add(Dense(len(alphabet_structures)))\n",
    "                    model.add(Activation('softmax'))\n",
    "\n",
    "                    optimizer = SGD(lr=learning_rate, momentum=momentum_val)\n",
    "\n",
    "                    model.compile(loss='categorical_crossentropy', optimizer=optimizer) \n",
    "                    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, train_size=0.1)\n",
    "                    model.fit(X_train, y_train, batch_size=128, epochs=10)\n",
    "                    test_filtered_x = np.array([X_test[i] for i in range(len(X_test)) if alphabet_structures[np.argmax(y_test[i])] != '*'])\n",
    "                    test_filtered_y = np.array([y_test[i] for i in range(len(y_test)) if alphabet_structures[np.argmax(y_test[i])] != '*'])\n",
    "                    predictions = (model.predict(test_filtered_x))\n",
    "                    predictions = [alphabet_structures[np.argmax(prediction)] for prediction in predictions]\n",
    "                    test_filtered_y = [alphabet_structures[np.argmax(y)] for y in test_filtered_y]\n",
    "                    print(\"TEST SET ACC:\")\n",
    "                    print(np.mean(np.array(predictions) == test_filtered_y))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
